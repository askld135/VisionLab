{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "root = \"C:/Users/w3218/Desktop/mipi/RGBW_training_dataset_fullres/\"\n",
    "sys.path.append(root)\n",
    "sys.path.append(\"./rgbw_rmsc_start_here/simple_ISP\")\n",
    "\n",
    "from data_scripts import process_function as pf\n",
    "\n",
    "crop_size = 256\n",
    "\n",
    "class Raw2RgbDataset(Dataset):\n",
    "    def __init__(self, raw_dir, gt_dir, db_type='train'):\n",
    "        self.raw_dir = raw_dir\n",
    "        self.raw_list = [os.path.join(raw_dir, f) for f in os.listdir(raw_dir)]\n",
    "        self.raw_list.sort()\n",
    "        \n",
    "        self.gt_dir = gt_dir\n",
    "        self.gt_list = [os.path.join(gt_dir, f) for f in os.listdir(gt_dir)]\n",
    "        self.gt_list.sort()\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.crop_size = 256\n",
    "        self.db_type = db_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_img_path = self.raw_list[idx]\n",
    "        raw_img = pf.read_bin_file(raw_img_path)\n",
    "        raw_tensor = self.to_tensor(raw_img) / 255.\n",
    "\n",
    "        gt_img_path = self.gt_list[idx]\n",
    "        gt_img = pf.read_bin_file(gt_img_path)\n",
    "        gt_tensor = self.to_tensor(gt_img) / 255.\n",
    "        \n",
    "        if self.db_type == 'train':\n",
    "            \n",
    "            raw_tensor, gt_tensor = self.random_crop(raw_tensor, gt_tensor)\n",
    "        \n",
    "            \n",
    "        return raw_tensor, gt_tensor\n",
    "\n",
    "    def random_crop(self, input, target):\n",
    "        h = input.size(-2)\n",
    "        w = input.size(-1)\n",
    "        \n",
    "        \n",
    "        rand_w = torch.randint((w - self.crop_size) // 4, [1, 1]) * 4\n",
    "        rand_h = torch.randint((h - self.crop_size) // 4, [1, 1]) * 4\n",
    "        \n",
    "        \n",
    "        input = input[:, rand_h : rand_h + self.crop_size, rand_w : rand_w + self.crop_size]\n",
    "        target = target[:, rand_h : rand_h + self. crop_size, rand_w : rand_w + self.crop_size]\n",
    "        \n",
    "        return input, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make binary file list\n",
    "input_0dB_dir = os.path.join(root, \"input/train_RGBW_full_input_0dB\")\n",
    "input_0dB_list = [os.path.join(input_0dB_dir, f) for f in os.listdir(input_0dB_dir)]\n",
    "\n",
    "input_24dB_dir = os.path.join(root, \"input/train_RGBW_full_input_24dB\")\n",
    "input_24dB_list = [os.path.join(input_24dB_dir, f) for f in os.listdir(input_24dB_dir)]\n",
    "\n",
    "input_42dB_dir = os.path.join(root, \"input/train_RGBW_full_input_42dB\")\n",
    "input_42dB_list = [os.path.join(input_42dB_dir, f) for f in os.listdir(input_42dB_dir)]\n",
    "\n",
    "input_0dB_list.sort()\n",
    "input_24dB_list.sort()\n",
    "input_42dB_list.sort()\n",
    "\n",
    "gt_dir = os.path.join(root, \"GT_bayer/train_bayer_full_gt\")\n",
    "gt_list = [os.path.join(gt_dir, f) for f in os.listdir(gt_dir)]\n",
    "\n",
    "gt_list.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/w3218/Desktop/mipi/RGBW_training_dataset_fullres/input/crops/image_0dB/image01_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\w3218\\Desktop\\mipi\\dataset_self.ipynb ì…€ 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/w3218/Desktop/mipi/dataset_self.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m image_42dB \u001b[39m=\u001b[39m image_42dB[rand_h : rand_h \u001b[39m+\u001b[39m crop_size, rand_w : rand_w \u001b[39m+\u001b[39m crop_size]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/w3218/Desktop/mipi/dataset_self.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m gt \u001b[39m=\u001b[39m gt[rand_h : rand_h \u001b[39m+\u001b[39m crop_size, rand_w : rand_w \u001b[39m+\u001b[39m crop_size]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/w3218/Desktop/mipi/dataset_self.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m pf\u001b[39m.\u001b[39;49msave_bin(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(root, \u001b[39m\"\u001b[39;49m\u001b[39minput/crops/image_0dB/image0\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m%\u001b[39;49m(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m,j)),image_0dB)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/w3218/Desktop/mipi/dataset_self.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m pf\u001b[39m.\u001b[39msave_bin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, \u001b[39m\"\u001b[39m\u001b[39minput/crops/image_24dB/image0\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,j)),image_24dB)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/w3218/Desktop/mipi/dataset_self.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m pf\u001b[39m.\u001b[39msave_bin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, \u001b[39m\"\u001b[39m\u001b[39minput/crops/image_42dB/image0\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,j)),image_42dB)\n",
      "File \u001b[1;32mc:\\Users\\w3218\\Desktop\\mipi\\data_scripts\\process_function.py:43\u001b[0m, in \u001b[0;36msave_bin\u001b[1;34m(filepath, arr)\u001b[0m\n\u001b[0;32m     40\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(arr, \u001b[39m0\u001b[39m, \u001b[39m1023\u001b[39m)\n\u001b[0;32m     41\u001b[0m height, width \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mshape\n\u001b[1;32m---> 43\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filepath, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m     44\u001b[0m     fp\u001b[39m.\u001b[39mwrite(struct\u001b[39m.\u001b[39mpack(\u001b[39m'\u001b[39m\u001b[39m<HH\u001b[39m\u001b[39m'\u001b[39m, width, height))\n\u001b[0;32m     45\u001b[0m     arr\u001b[39m.\u001b[39mtofile(fp)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/w3218/Desktop/mipi/RGBW_training_dataset_fullres/input/crops/image_0dB/image01_1'"
     ]
    }
   ],
   "source": [
    "for i in range(len(gt_list)):\n",
    "    image_0dB = pf.read_bin_file(input_0dB_list[i])\n",
    "    image_24dB = pf.read_bin_file(input_24dB_list[i]) \n",
    "    image_42dB = pf.read_bin_file(input_42dB_list[i])\n",
    "    gt = pf.read_bin_file(gt_list[i])\n",
    "    for j in range(1, 101):\n",
    "        h = image_0dB.shape[-2]\n",
    "        w = image_0dB.shape[-1]\n",
    "        if h <= crop_size or w <= crop_size:\n",
    "            rand_h = 0\n",
    "            rand_w = 0\n",
    "        else:\n",
    "            rand_h = np.random.randint(0, (h - crop_size) // 4) * 4\n",
    "            rand_w = np.random.randint(0, (w - crop_size) // 4) * 4\n",
    "        \n",
    "        image_0dB = image_0dB[rand_h : rand_h + crop_size, rand_w : rand_w + crop_size]\n",
    "        image_24dB = image_24dB[rand_h : rand_h + crop_size, rand_w : rand_w + crop_size]\n",
    "        image_42dB = image_42dB[rand_h : rand_h + crop_size, rand_w : rand_w + crop_size]\n",
    "        gt = gt[rand_h : rand_h + crop_size, rand_w : rand_w + crop_size]\n",
    "       \n",
    "        pf.save_bin(os.path.join(root, \"input/crops/image_0dB/image0%d_%d\"%(i+1,j)),image_0dB)\n",
    "        pf.save_bin(os.path.join(root, \"input/crops/image_24dB/image0%d_%d\"%(i+1,j)),image_24dB)\n",
    "        pf.save_bin(os.path.join(root, \"input/crops/image_42dB/image0%d_%d\"%(i+1,j)),image_42dB)\n",
    "        pf.save_bin(os.path.join(root, \"input/crops/image0%d_%d\"%(i+1,j)),gt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b9e9eb141a3a97614cb39e60c2bee3c3b2784b0bf79b3ae581059f583c5b890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
