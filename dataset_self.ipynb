{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "root = \"/RGBW_training_dataset_fullres/\"\n",
    "sys.path.append(root)\n",
    "sys.path.append(\"C:/Users/w3218/Desktop/mipi/RGBW_training_dataset_fullres/rgbw_rmsc_start_here\")\n",
    "\n",
    "from data_scripts import process_function as pf\n",
    "\n",
    "crop_size = 256\n",
    "\n",
    "class Raw2RgbDataset(Dataset):\n",
    "    def __init__(self, raw_dir, gt_dir, db_type='train'):\n",
    "        self.raw_dir = raw_dir\n",
    "        self.raw_list = [os.path.join(raw_dir, f) for f in os.listdir(raw_dir)]\n",
    "        self.raw_list.sort()\n",
    "        \n",
    "        self.gt_dir = gt_dir\n",
    "        self.gt_list = [os.path.join(gt_dir, f) for f in os.listdir(gt_dir)]\n",
    "        self.gt_list.sort()\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.crop_size = 256\n",
    "        self.db_type = db_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_img_path = self.raw_list[idx]\n",
    "        raw_img = pf.read_bin_file(raw_img_path)\n",
    "        raw_tensor = self.to_tensor(raw_img) / 255.\n",
    "\n",
    "        gt_img_path = self.gt_list[idx]\n",
    "        gt_img = pf.read_bin_file(gt_img_path)\n",
    "        gt_tensor = self.to_tensor(gt_img) / 255.\n",
    "        \n",
    "        if self.db_type == 'train':\n",
    "            \n",
    "            raw_tensor, gt_tensor = self.random_crop(raw_tensor, gt_tensor)\n",
    "        \n",
    "            \n",
    "        return raw_tensor, gt_tensor\n",
    "\n",
    "    def random_crop(self, input, target):\n",
    "        h = input.size(-2)\n",
    "        w = input.size(-1)\n",
    "        \n",
    "        \n",
    "        rand_w = torch.randint((w - self.crop_size) // 4, [1, 1]) * 4\n",
    "        rand_h = torch.randint((h - self.crop_size) // 4, [1, 1]) * 4\n",
    "        \n",
    "        \n",
    "        input = input[:, rand_h : rand_h + self.crop_size, rand_w : rand_w + self.crop_size]\n",
    "        target = target[:, rand_h : rand_h + self. crop_size, rand_w : rand_w + self.crop_size]\n",
    "        \n",
    "        return input, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make binary file list\n",
    "input_0dB_dir = os.path.join(root, \"input/train_RGBW_full_input_0dB\")\n",
    "input_0dB_list = [os.path.join(input_0dB_dir, f) for f in os.listdir(input_0dB_dir)]\n",
    "\n",
    "input_24dB_dir = os.path.join(root, \"input/train_RGBW_full_input_24dB\")\n",
    "input_24dB_list = [os.path.join(input_24dB_dir, f) for f in os.listdir(input_24dB_dir)]\n",
    "\n",
    "input_42dB_dir = os.path.join(root, \"input/train_RGBW_full_input_42dB\")\n",
    "input_42dB_list = [os.path.join(input_42dB_dir, f) for f in os.listdir(input_42dB_dir)]\n",
    "\n",
    "input_0dB_list.sort()\n",
    "input_24dB_list.sort()\n",
    "input_42dB_list.sort()\n",
    "\n",
    "gt_dir = os.path.join(root, \"GT_bayer/train_bayer_full_gt\")\n",
    "gt_list = [os.path.join(gt_dir, f) for f in os.listdir(gt_dir)]\n",
    "\n",
    "gt_list.sort()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(gt_list)):\n",
    "    image_0dB = pf.read_bin_file(input_0dB_list[i])\n",
    "    image_24dB = pf.read_bin_file(input_24dB_list[i]) \n",
    "    image_42dB = pf.read_bin_file(input_42dB_list[i])\n",
    "    gt = pf.read_bin_file(gt_list[i])\n",
    "    for j in range(1, 101):\n",
    "        h = image_0dB.shape[-2]\n",
    "        w = image_0dB.shape[-1]\n",
    "        if h <= crop_size or w <= crop_size:\n",
    "            rand_h = 0\n",
    "            rand_w = 0\n",
    "        else:\n",
    "            rand_h = np.random.randint(0, (h - crop_size) // 4) * 4\n",
    "            rand_w = np.random.randint(0, (w - crop_size) // 4) * 4\n",
    "        \n",
    "        image_0dB = image_0dB[rand_h : rand_h + crop_size, rand_w : rand_w + crop_size]\n",
    "        image_24dB = image_24dB[rand_h : rand_h + crop_size, rand_w : rand_w + crop_size]\n",
    "        image_42dB = image_42dB[rand_h : rand_h + crop_size, rand_w : rand_w + crop_size]\n",
    "        gt = gt[rand_h : rand_h + crop_size, rand_w : rand_w + crop_size]\n",
    "       \n",
    "        pf.save_bin(os.path.join(root, \"input/crops/image_0dB/image0%d_%d\"%(i+1,j)),image_0dB)\n",
    "        pf.save_bin(os.path.join(root, \"input/crops/image_24dB/image0%d_%d\"%(i+1,j)),image_24dB)\n",
    "        pf.save_bin(os.path.join(root, \"input/crops/image_42dB/image0%d_%d\"%(i+1,j)),image_42dB)\n",
    "        pf.save_bin(os.path.join(root, \"input/crops/image0%d_%d\"%(i+1,j)),gt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b9e9eb141a3a97614cb39e60c2bee3c3b2784b0bf79b3ae581059f583c5b890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
